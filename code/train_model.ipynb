{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Model Tuning & Training</h1>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">\n",
    "\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  d:\\dlss-project24/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import Checkpoint\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from datetime import datetime\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "    local_path = \"/content/drive/MyDrive/DLSS/\"\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "    local_path = \"d:\\dlss-project24/\" #os.getcwd() \n",
    "\n",
    "print(\"CWD: \", local_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create context-target pairs\n",
    "def create_context_target_pairs_cbow(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(context_size, len(sentence) - context_size):\n",
    "            context = sentence[i - context_size:i] + sentence[i + 1:i + context_size + 1]\n",
    "            target = sentence[i]\n",
    "            pairs.append((context, target))\n",
    "    return pairs\n",
    "\n",
    "# Function to create context-target pairs for Skip-gram\n",
    "def create_context_target_pairs_skipgram(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(len(sentence)):\n",
    "            target = sentence[i]\n",
    "            context = sentence[max(0, i - context_size):i] + sentence[i + 1:i + context_size + 1]\n",
    "            for ctx in context:\n",
    "                pairs.append((target, ctx))\n",
    "    return pairs\n",
    "\n",
    "# Dataset and DataLoader definition\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, pairs, word_to_index):\n",
    "        self.pairs = pairs\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.pairs[idx]\n",
    "        context_idxs = torch.tensor([self.word_to_index[word] for word in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor(self.word_to_index[target], dtype=torch.long)\n",
    "        return context_idxs, target_idx\n",
    "    \n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Class that implements early stopping to halt training when the validation loss stops improving.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    __call__(val_loss, model)\n",
    "        Checks if the validation loss has improved and updates the state of early stopping.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "    counter : int\n",
    "        Counter for the number of epochs since the last improvement.\n",
    "    best_loss : float or None\n",
    "        Best recorded validation loss.\n",
    "    early_stop : bool\n",
    "        Indicating whether training should be stopped early.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience= int, min_delta= float):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        ## for the first training iteration\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            ## check if the loss decreased, if not:\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            ## if loss decrease (more than the defined delta): save model parameters, reset counter and update best loss\n",
    "        else:\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "\n",
    "\n",
    "def train_model(config, data):\n",
    "    \"\"\"\n",
    "    Function that trains a model using the specified configuration and data, implements early stopping based on validation loss improvement, and reports training progress and results to Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    config : dict\n",
    "        Dictionary containing hyperparameters and settings for the model, training, and early stopping.\n",
    "    data : tuple\n",
    "        Tuple containing training and validation datasets.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dict\n",
    "        A dictionary containing the final training loss, validation loss, accuracy, the epoch at which training stopped,\n",
    "        and lists of validation and training losses across epochs.\n",
    "    \"\"\"\n",
    "    train_dataset, val_dataset, vocab_size = data\n",
    "    \n",
    "    ## set seed to replicate the model\n",
    "    torch.manual_seed(1234)\n",
    "\n",
    "    ## empty lists to store loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    ## initialise model\n",
    "    model = MLP_embeddings(vocab_size, config[\"embedding_dim\"]).to(device)\n",
    "        \n",
    "    ## loss criterion\n",
    "    loss_criterion = nn.NLLLoss()\n",
    "\n",
    "    ## choose optimiser\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    ## adapt learning rate with scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "\n",
    "    #### Data ####\n",
    "    ## wrap data into data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, generator = torch.Generator().manual_seed(1234))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    #### Early Stopper ####\n",
    "    early_stopper = EarlyStopping(patience= config[\"patience\"], min_delta = config[\"min_delta\"])\n",
    "\n",
    "    #### Training ####\n",
    "    ## each epoch iterates through the whole dataset\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        ## train model on training set\n",
    "        model.train()\n",
    "        ## set loss and r2 to zero again so we start fresh\n",
    "        train_loss = 0\n",
    "        ## iterate through batches of the training data (data is the features and target the target)\n",
    "        for context_idxs, target_idx in train_loader:\n",
    "            ## send tensors to gpu\n",
    "            context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "            ## reset gradient to 0,start fresh again\n",
    "            optimizer.zero_grad()\n",
    "            ## predict target\n",
    "            log_probs = model(context_idxs)\n",
    "            ## caculate loss\n",
    "            loss = loss_criterion(log_probs, target_idx)\n",
    "            ## caculate gradients\n",
    "            loss.backward()\n",
    "            ## update weights\n",
    "            optimizer.step()\n",
    "            ## sum loss for all batches together\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "\n",
    "\n",
    "        #### Validation ####\n",
    "        ## check performance on validation set\n",
    "        model.eval()\n",
    "        ## set loss to zero again so we start fresh\n",
    "        val_loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        ## as we test on the validation set, we do not want to update our weights now\n",
    "        with torch.no_grad():\n",
    "            for context_idxs, target_idx in val_loader:\n",
    "                ## send tensors to gpu\n",
    "                context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "                log_probs = model(context_idxs)\n",
    "                ## caculate loss\n",
    "                loss = loss_criterion(log_probs, target_idx)\n",
    "                ## sum loss for whole epoch\n",
    "                val_loss_sum += loss.item()\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        ## adapt learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ## save checkpoints only if loss decreased and the epoch is larger than the patience (to save less checkpoints) but always report metrics to ray\n",
    "        if epoch > 0 and early_stopper.best_loss - config[\"min_delta\"]  > val_loss:\n",
    "          ##save checkpoint\n",
    "          torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "\n",
    "          ## report mertrics and save checkpoint\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2),\n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses\n",
    "                      # \"accuracy\": accuracy\n",
    "                      },\n",
    "                  checkpoint=Checkpoint.from_directory(\".\")\n",
    "                  )\n",
    "        else:\n",
    "          ##report only metrics\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2), \n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses\n",
    "\n",
    "                      #\"accuracy\": accuracy\n",
    "                      }\n",
    "                  )\n",
    "\n",
    "        #### Early stopping ####\n",
    "        # check if loss decreases more than defined threshold\n",
    "        early_stopper(val_loss, model)\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "\n",
    "    ## last checkpoint\n",
    "    torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "    ray.train.report(\n",
    "        {\"loss\": round(early_stopper.best_loss, 3), \"epoch\": int(epoch)},\n",
    "        checkpoint=Checkpoint.from_directory(\".\")\n",
    "        )\n",
    "\n",
    "    #return train_losses, val_losses, val_r2s\n",
    "    return {\n",
    "        \"loss\": round(early_stopper.best_loss, 2), \n",
    "        #\"accuracy\": accuracy, \n",
    "        \"val_loss_list\": val_losses, \n",
    "        \"train_loss_list\": train_losses\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "#### Tuning ####\n",
    "## Custom function to shorten ray file path names\n",
    "def short_dirname(trial) -> str:\n",
    "    \"\"\"\n",
    "    Function that shortens path names created by Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    trial : ray.tune.Trial\n",
    "        The Ray trial object for which the directory name is being created.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    str\n",
    "        A shortened file path in the format 'trial_<trial_id>'.\n",
    "    \"\"\"\n",
    "    return \"trial_\" + str(trial.trial_id)\n",
    "\n",
    "\n",
    "## actual tuning\n",
    "def tune_parameters(training_function, num_samples, train_dataset, val_dataset, vocab_size, max_num_epochs, parameter_space, resources, local_path):\n",
    "    \"\"\"\n",
    "    Function that tunes the hyperparameters for a DL model using ASHA scheduling and saves the best model and tuning results locally.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    training_function : function\n",
    "        The function used for training the model during hyperparameter tuning.\n",
    "    num_samples : int\n",
    "        The number of hyperparameter samples to try.\n",
    "    train_dataset : object\n",
    "        Training dataset object.\n",
    "    val_dataset : object\n",
    "        Validation dataset object.\n",
    "    max_num_epochs : int\n",
    "        The maximum number of epochs for training each model.\n",
    "    parameter_space : dict\n",
    "        Dictionary defining the hyperparameter search space.\n",
    "    resources : dict\n",
    "        Resources configuration for training.\n",
    "    local_path : str\n",
    "        Local path to save tuning results and best model.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the tuning results, sorted by loss.\n",
    "        \"\"\"\n",
    "\n",
    "    ## because min number of epochs in sampling range is 50\n",
    "    #assert max_num_epochs > 50\n",
    "\n",
    "    ## Hyperparameters to sample from\n",
    "    ## ASHA scheduler to increase efficiency and stop inefficient training configs\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=3,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    ## tuning function, choose resources\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                training_function,\n",
    "                data = (train_dataset, val_dataset, vocab_size)),\n",
    "                resources= resources\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "            trial_dirname_creator=short_dirname\n",
    "        ),\n",
    "        param_space= parameter_space,\n",
    "        run_config = ray.train.RunConfig(storage_path = local_path, name=\"run_\" + datetime.now().strftime(\"%m-%d_%H_%M\"))\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "\n",
    "    #### Best Model ####\n",
    "    ## get best model\n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    ## save info about best model\n",
    "    with open(local_path + '/best_models/best_result_info_' + parameter_space[\"model\"] + '.pkl', 'wb') as file:\n",
    "        pickle.dump(best_result, file)\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"loss\"]))\n",
    "\n",
    "    ## get path to that best model\n",
    "    best_checkpoint_path = best_result.get_best_checkpoint(metric = \"loss\", mode = \"min\").path + \"/checkpoint_\"+ parameter_space[\"model\"] + \".pt\"\n",
    "    ## save path to model as txt\n",
    "    with open(local_path + f\"/best_models/path_best_model_\" + parameter_space[\"model\"] + \".txt\", \"w\") as file:\n",
    "        file.write(best_checkpoint_path)\n",
    "\n",
    "\n",
    "    #### Tuning Overview ####\n",
    "    ## Get results as df\n",
    "    df_tuning_results = results.get_dataframe()\n",
    "    ## Rename cols\n",
    "    df_tuning_results.columns = [col.replace('config/', '') for col in df_tuning_results.columns]\n",
    "    ## sort by loss\n",
    "    df_tuning_results.sort_values(\"loss\", inplace = True)\n",
    "    ## Save only relevant cols\n",
    "    df_tuning_results = df_tuning_results[['loss', 'lr', 'batch_size', 'epochs',\n",
    "                                           'patience', 'min_delta', \"gamma\", \"step_size\", \n",
    "                                           \"dropout\", 'time_total_s', \"val_loss_list\", \"train_loss_list\"]]\n",
    "    ## Save as csv\n",
    "    df_tuning_results.to_csv(local_path + \"df_tuning_results.csv\")\n",
    "\n",
    "    return df_tuning_results\n",
    "\n",
    "\n",
    " #### Replication ####\n",
    "def load_best_model(model_type = str, local_path = str):\n",
    "    \"\"\"\n",
    "    Function that loads the best model based on the specified model type.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model to load (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    torch.nn.Module\n",
    "        The best pre-trained model loaded on the device and ready for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get best config\n",
    "    with open(f'{local_path}/tuning_results/best_models/best_result_info_{model_type}.pkl', 'rb') as file:\n",
    "    # Use pickle.dump() to write the data object to file\n",
    "        best_result = pickle.load(file)\n",
    "\n",
    "    with open(f\"{local_path}/tuning_results/best_models/path_best_model_{model_type}.txt\") as file:\n",
    "        path_best_file = file.read()\n",
    "\n",
    "    ## load parameters of best model\n",
    "    best_checkpoint = torch.load(path_best_file)\n",
    "\n",
    "    ## create new model\n",
    "    model_final = MLP_embeddings(\n",
    "        vocab_size = vocab_size, \n",
    "        embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "    ## load parameteres of best checkpoint\n",
    "    model_final.load_state_dict(best_checkpoint)\n",
    "    ## model into evaluation mode\n",
    "    model_final.eval()\n",
    "    model_final.to(device)\n",
    "\n",
    "    return model_final\n",
    "\n",
    "\n",
    "def plot_loss_curve(model_type = str, local_path = str):\n",
    "    \n",
    "   \"\"\"\n",
    "    Function that plots the training and validation loss curves of the best model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model whose loss curve to plot (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "   ## get file with loss data\n",
    "   with open(local_path + f'/tuning_results/best_models/best_result_info_{model_type}.pkl', 'rb') as file:\n",
    "       best_result = pickle.load(file)\n",
    "\n",
    "   ## get respective tuning data\n",
    "   val_losses = best_result.metrics[\"val_loss_list\"]\n",
    "   ## i forgot to divide the train loss by n in the training function\n",
    "   ## and repeating that takes 8 hours, so I have to do it like this now\n",
    "   train_losses = best_result.metrics[\"train_loss_list\"]\n",
    "\n",
    "   ## create plot\n",
    "   plt.plot(train_losses, label='Training Loss')\n",
    "   plt.plot(val_losses, label='Validation Loss')\n",
    "   plt.title(f\"{model_type} loss curves\")\n",
    "   plt.xlabel('Epochs')\n",
    "   plt.ylabel('Loss')\n",
    "   plt.legend()\n",
    "   ## save\n",
    "   plt.savefig(local_path + f\"plots/loss_curve_{model_type}.png\")\n",
    "   plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14818"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get data\n",
    "comments = pd.read_csv(local_path +\"data/preprocessed/comments.csv\")\n",
    "\n",
    "# Splitting the data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(comments, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "#Adding all comments for generating the vocabulary. If not an error occurs when tokens missing\n",
    "total_comments_list = comments[\"cleaned\"].dropna().astype(str).tolist()\n",
    "\n",
    "train_list = train_df[\"cleaned\"].dropna().astype(str).tolist()\n",
    "val_list = val_df[\"cleaned\"].dropna().astype(str).tolist()\n",
    "test_list = test_df[\"cleaned\"].dropna().astype(str).tolist()\n",
    "\n",
    "# Ensure each entry is a string and split each sentence into words\n",
    "total_corpus = [doc.split() for doc in total_comments_list]\n",
    "corpus_train = [doc.split() for doc in train_list]\n",
    "corpus_val = [doc.split() for doc in val_list]\n",
    "corpus_test = [doc.split() for doc in test_list]\n",
    "\n",
    "# Create a vocabulary: count occurrences of each word\n",
    "vocab = defaultdict(int)\n",
    "for sentence in total_corpus:\n",
    "    for word in sentence:\n",
    "        vocab[word] += 1\n",
    "\n",
    "# Remove infrequent words from the vocabulary\n",
    "min_count = 1\n",
    "vocab = {word: count for word, count in vocab.items() if count >= min_count}\n",
    "\n",
    "# Create word to index and index to word mappings\n",
    "word_to_index = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "# Create DataFrame from vocabulary\n",
    "vocab_df = pd.DataFrame(list(vocab.items()), columns=['Word', 'Count'])\n",
    "\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 2\n",
    "train_pairs_cbow = create_context_target_pairs_cbow(corpus_train, context_size)\n",
    "val_pairs_cbow = create_context_target_pairs_cbow(corpus_val, context_size)\n",
    "test_pairs_cbow = create_context_target_pairs_cbow(corpus_test, context_size)\n",
    "\n",
    "\n",
    "train_dataset_cbow = Word2VecDataset(train_pairs_cbow, word_to_index)\n",
    "val_dataset_cbow = Word2VecDataset(val_pairs_cbow, word_to_index)\n",
    "test_dataset_cbow = Word2VecDataset(test_pairs_cbow, word_to_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs_skip = create_context_target_pairs_skipgram(corpus_train, context_size)\n",
    "val_pairs_skip = create_context_target_pairs_skipgram(corpus_val, context_size)\n",
    "test_pairs_skip = create_context_target_pairs_skipgram(corpus_test, context_size)\n",
    "\n",
    "train_dataset_skip = Word2VecDataset(train_pairs_skip, word_to_index)\n",
    "val_dataset_skip = Word2VecDataset(val_pairs_skip, word_to_index)\n",
    "test_dataset_skip = Word2VecDataset(test_pairs_skip, word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## use the gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#### Continuous bag of words model #####\n",
    "class MLP_embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(MLP_embeddings, self).__init__()\n",
    "        # Embedding layer for word indices\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Linear layer for mapping embeddings to vocab size\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # Get embeddings for context words\n",
    "        embeds = self.embeddings(context)\n",
    "        # Average embeddings to get a single vector\n",
    "        combined = torch.mean(embeds, dim=1)\n",
    "        # Apply dropout and pass through linear layer\n",
    "        out = self.linear1(self.dropout(combined))\n",
    "        # Compute log probabilities\n",
    "        log_probs = torch.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tuning ####\n",
    "## choose sample size and max epoch\n",
    "n_samples = 2\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 19:00:54</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:25.01        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.4/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 2.000: -7.57 | Iter 1.000: nan<br>Logical resource usage: 2.0/8 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:GTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  min_delta</th><th style=\"text-align: right;\">  patience</th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_6fa5b_00000</td><td>TERMINATED</td><td>127.0.0.1:18336</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\"> 0.210529</td><td style=\"text-align: right;\">            250</td><td style=\"text-align: right;\">     170</td><td style=\"text-align: right;\">   0.75</td><td style=\"text-align: right;\">0.000567616</td><td style=\"text-align: right;\"> 0.00175097</td><td style=\"text-align: right;\">        15</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.00019206 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         112.981</td><td style=\"text-align: right;\">  7.45</td></tr>\n",
       "<tr><td>train_model_6fa5b_00001</td><td>TERMINATED</td><td>127.0.0.1:9184 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\"> 0.368644</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">      90</td><td style=\"text-align: right;\">   0.1 </td><td style=\"text-align: right;\">0.000347983</td><td style=\"text-align: right;\"> 0.00173921</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000415519</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         137.482</td><td style=\"text-align: right;\">  7.69</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "\u001b[36m(train_model pid=18336)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-08_18_58/trial_6fa5b_00000/checkpoint_000000)\n",
      "\u001b[36m(train_model pid=9184)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-08_18_58/trial_6fa5b_00001/checkpoint_000000)\n",
      "2024-08-08 19:00:54,297\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-08-08 19:00:54,305\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to 'd:/dlss-project24/tuning_results/run_08-08_18_58' in 0.0126s.\n",
      "2024-08-08 19:00:54,430\tINFO tune.py:1039 -- Total run time: 145.17 seconds (145.00 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'model': 'CBOW', 'dropout': 0.21052923790800432, 'lr': 0.000567616204855433, 'batch_size': 128, 'epochs': 170, 'patience': 15, 'min_delta': 0.0017509735671179076, 'gamma': 0.75, 'step_size': 10, 'weight_decay': 0.00019205986223548723, 'embedding_dim': 250}\n",
      "Best trial final validation loss: 7.45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patience</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>step_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>val_loss_list</th>\n",
       "      <th>train_loss_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.45</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>128</td>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>0.210529</td>\n",
       "      <td>112.980836</td>\n",
       "      <td>[7.448712313128083, 7.181726695049422]</td>\n",
       "      <td>[8.078955405510513, 7.17212345136092]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.69</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>32</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>137.481527</td>\n",
       "      <td>[7.687333355553662, 7.365984861504076]</td>\n",
       "      <td>[8.520784224142933, 7.4375243246993135]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss        lr  batch_size  epochs  patience  min_delta  gamma  step_size  \\\n",
       "0  7.45  0.000568         128     170        15   0.001751   0.75         10   \n",
       "1  7.69  0.000348          32      90        10   0.001739   0.10         10   \n",
       "\n",
       "    dropout  time_total_s                           val_loss_list  \\\n",
       "0  0.210529    112.980836  [7.448712313128083, 7.181726695049422]   \n",
       "1  0.368644    137.481527  [7.687333355553662, 7.365984861504076]   \n",
       "\n",
       "                           train_loss_list  \n",
       "0    [8.078955405510513, 7.17212345136092]  \n",
       "1  [8.520784224142933, 7.4375243246993135]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    train_dataset = train_dataset_cbow,\n",
    "    val_dataset = val_dataset_cbow,\n",
    "    vocab_size= vocab_size,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1/2},\n",
    "    parameter_space = {\n",
    "            \"model\": \"CBOW\",\n",
    "            \"dropout\": tune.loguniform(0.1, 0.5),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "            \"epochs\": tune.choice(list(range(50, 200, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([50, 100, 250, 500, 750, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curve(\"CBOW\", local_path = local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CBOW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_best_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBOW\u001b[39m\u001b[38;5;124m\"\u001b[39m, local_path \u001b[38;5;241m=\u001b[39m local_path)\n",
      "Cell \u001b[1;32mIn[2], line 387\u001b[0m, in \u001b[0;36mload_best_model\u001b[1;34m(model_type, local_path)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m## create new model\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBOW\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     model_final \u001b[38;5;241m=\u001b[39m CBOW(\n\u001b[0;32m    388\u001b[0m         vocab_size \u001b[38;5;241m=\u001b[39m vocab_size, \n\u001b[0;32m    389\u001b[0m         embedding_dim \u001b[38;5;241m=\u001b[39m best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    390\u001b[0m         )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m     model_final \u001b[38;5;241m=\u001b[39m MLP(l1 \u001b[38;5;241m=\u001b[39m best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m], l2 \u001b[38;5;241m=\u001b[39m best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CBOW' is not defined"
     ]
    }
   ],
   "source": [
    "load_best_model(\"CBOW\", local_path = local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 19:01:23</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:11.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.0/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 2.0/8 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:GTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_d0331_00000</td><td style=\"text-align: right;\">           1</td><td>C:/Users/weitz/AppData/Local/Temp/ray/session_2024-08-08_18-58-24_097398_18176/artifacts/2024-08-08_19-01-11/run_08-08_19_01/driver_artifacts/trial_d0331_00000/error.txt</td></tr>\n",
       "<tr><td>train_model_d0331_00001</td><td style=\"text-align: right;\">           1</td><td>C:/Users/weitz/AppData/Local/Temp/ray/session_2024-08-08_18-58-24_097398_18176/artifacts/2024-08-08_19-01-11/run_08-08_19_01/driver_artifacts/trial_d0331_00001/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  min_delta</th><th style=\"text-align: right;\">  patience</th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_d0331_00000</td><td>ERROR   </td><td>127.0.0.1:15840</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\"> 0.100581</td><td style=\"text-align: right;\">            500</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">   0.5 </td><td style=\"text-align: right;\">0.00459759</td><td style=\"text-align: right;\">0.000144657</td><td style=\"text-align: right;\">        15</td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">    0.00253645</td></tr>\n",
       "<tr><td>train_model_d0331_00001</td><td>ERROR   </td><td>127.0.0.1:8728 </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\"> 0.103448</td><td style=\"text-align: right;\">            500</td><td style=\"text-align: right;\">     170</td><td style=\"text-align: right;\">   0.75</td><td style=\"text-align: right;\">0.003367  </td><td style=\"text-align: right;\">0.00259035 </td><td style=\"text-align: right;\">         5</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">    0.00233821</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 19:01:22,793\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_d0331_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=8728, ip=127.0.0.1, actor_id=2ec06c844688d9773b4fb7cd01000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1887, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1828, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 145, in train_model\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 33, in __getitem__\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 33, in <listcomp>\n",
      "KeyError: 'n'\n",
      "2024-08-08 19:01:23,008\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_d0331_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py\", line 861, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=15840, ip=127.0.0.1, actor_id=c6079b1fd6f2ac6cdbdf4c2601000000, repr=train_model)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1887, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1828, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\trainable\\util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 145, in train_model\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 33, in __getitem__\n",
      "  File \"C:\\Users\\weitz\\AppData\\Local\\Temp\\ipykernel_18176\\1910493130.py\", line 33, in <listcomp>\n",
      "KeyError: 'n'\n",
      "2024-08-08 19:01:23,080\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-08-08 19:01:23,133\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to 'd:/dlss-project24/tuning_results/run_08-08_19_01' in 0.1175s.\n",
      "2024-08-08 19:01:23,154\tERROR tune.py:1035 -- Trials did not complete: [train_model_d0331_00000, train_model_d0331_00001]\n",
      "2024-08-08 19:01:23,156\tINFO tune.py:1039 -- Total run time: 11.90 seconds (11.73 seconds for the tuning loop).\n",
      "2024-08-08 19:01:23,910\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m## tune\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tune_parameters(\n\u001b[0;32m      6\u001b[0m     train_model,\n\u001b[0;32m      7\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[0;32m      8\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m train_dataset_skip,\n\u001b[0;32m      9\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m val_dataset_skip,\n\u001b[0;32m     10\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m vocab_size,\n\u001b[0;32m     11\u001b[0m     max_num_epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     12\u001b[0m     resources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m},\n\u001b[0;32m     13\u001b[0m     parameter_space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipgram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m2048\u001b[39m]),\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m10\u001b[39m))),\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m]),\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_delta\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m),\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]),\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m]),\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m),\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m250\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m750\u001b[39m, \u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m     25\u001b[0m             },\n\u001b[0;32m     26\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m local_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tuning_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[2], line 325\u001b[0m, in \u001b[0;36mtune_parameters\u001b[1;34m(training_function, num_samples, train_dataset, val_dataset, vocab_size, max_num_epochs, parameter_space, resources, local_path)\u001b[0m\n\u001b[0;32m    320\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m#### Best Model ####\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m## get best model\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m best_result \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget_best_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m## save info about best model\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(local_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/best_models/best_result_info_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m parameter_space[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\weitz\\anaconda3\\Lib\\site-packages\\ray\\tune\\result_grid.py:161\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    150\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    train_dataset = train_dataset_skip,\n",
    "    val_dataset = val_dataset_skip,\n",
    "    vocab_size= vocab_size,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1/2},\n",
    "    parameter_space = {\n",
    "            \"model\": \"skipgram\",\n",
    "            \"dropout\": tune.loguniform(0.1, 0.5),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "            \"epochs\": tune.choice(list(range(50, 200, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([50, 100, 250, 500, 750, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(\"skipgram\", local_path = local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_best_model(\"skipgram\", local_path = local_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
