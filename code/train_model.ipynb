{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Model Tuning & Training</h1>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">\n",
    "\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  d:\\dlss-project24/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import Checkpoint\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from datetime import datetime\n",
    "import os \n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "    local_path = \"/content/drive/MyDrive/DLSS/\"\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "    local_path = \"d:\\dlss-project24/\" #os.getcwd() \n",
    "\n",
    "print(\"CWD: \", local_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create context-target pairs\n",
    "def create_context_target_pairs_cbow(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(context_size, len(sentence) - context_size):\n",
    "            context = sentence[i - context_size:i] + sentence[i + 1:i + context_size + 1]\n",
    "            target = sentence[i]\n",
    "            pairs.append((context, target))\n",
    "    return pairs\n",
    "\n",
    "# Function to create context-target pairs for Skip-gram\n",
    "def create_context_target_pairs_skipgram(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(len(sentence)):\n",
    "            target = sentence[i]\n",
    "            context = sentence[max(0, i - context_size):i] + sentence[i + 1:i + context_size + 1]\n",
    "            for ctx in context:\n",
    "                pairs.append((target, ctx))\n",
    "    return pairs\n",
    "\n",
    "# Dataset and DataLoader definition\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, pairs, word_to_index):\n",
    "        self.pairs = pairs\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.pairs[idx]\n",
    "        context_idxs = torch.tensor([self.word_to_index[word] for word in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor(self.word_to_index[target], dtype=torch.long)\n",
    "        return context_idxs, target_idx\n",
    "    \n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Class that implements early stopping to halt training when the validation loss stops improving.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    __call__(val_loss, model)\n",
    "        Checks if the validation loss has improved and updates the state of early stopping.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "    counter : int\n",
    "        Counter for the number of epochs since the last improvement.\n",
    "    best_loss : float or None\n",
    "        Best recorded validation loss.\n",
    "    early_stop : bool\n",
    "        Indicating whether training should be stopped early.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience= int, min_delta= float):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        ## for the first training iteration\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            ## check if the loss decreased, if not:\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            ## if loss decrease (more than the defined delta): save model parameters, reset counter and update best loss\n",
    "        else:\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "\n",
    "\n",
    "def train_model(config, data):\n",
    "    \"\"\"\n",
    "    Function that trains a model using the specified configuration and data, implements early stopping based on validation loss improvement, and reports training progress and results to Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    config : dict\n",
    "        Dictionary containing hyperparameters and settings for the model, training, and early stopping.\n",
    "    data : tuple\n",
    "        Tuple containing training and validation datasets.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dict\n",
    "        A dictionary containing the final training loss, validation loss, accuracy, the epoch at which training stopped,\n",
    "        and lists of validation and training losses across epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    filtered_corpus_train, filtered_corpus_val, word_to_index = data\n",
    "    \n",
    "    train_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_train, config[\"context_size\"])\n",
    "    val_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_val, config[\"context_size\"])\n",
    "    #test_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_test, config[\"context_size\"])\n",
    "\n",
    "\n",
    "    train_dataset_cbow = Word2VecDataset(train_pairs_cbow, word_to_index)\n",
    "    val_dataset_cbow = Word2VecDataset(val_pairs_cbow, word_to_index)\n",
    "    #test_dataset_cbow = Word2VecDataset(test_pairs_cbow, word_to_index)\n",
    "\n",
    "\n",
    "    \n",
    "    ## set seed to replicate the model\n",
    "    torch.manual_seed(1234)\n",
    "\n",
    "    ## empty lists to store loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    ## initialise model\n",
    "    model = MLP_embeddings(len(word_to_index), config[\"embedding_dim\"]).to(device)\n",
    "        \n",
    "    ## loss criterion\n",
    "    loss_criterion = nn.NLLLoss()\n",
    "\n",
    "    ## choose optimiser\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    ## adapt learning rate with scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "\n",
    "    #### Data ####\n",
    "    ## wrap data into data loaders\n",
    "    train_loader = DataLoader(train_dataset_cbow, batch_size=config[\"batch_size\"], shuffle=True, generator = torch.Generator().manual_seed(1234))\n",
    "    val_loader = DataLoader(val_dataset_cbow, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    #### Early Stopper ####\n",
    "    early_stopper = EarlyStopping(patience= config[\"patience\"], min_delta = config[\"min_delta\"])\n",
    "\n",
    "    #### Training ####\n",
    "    ## each epoch iterates through the whole dataset\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        ## train model on training set\n",
    "        model.train()\n",
    "        ## set loss and r2 to zero again so we start fresh\n",
    "        train_loss = 0\n",
    "        ## iterate through batches of the training data (data is the features and target the target)\n",
    "        for context_idxs, target_idx in train_loader:\n",
    "            ## send tensors to gpu\n",
    "            context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "            ## reset gradient to 0,start fresh again\n",
    "            optimizer.zero_grad()\n",
    "            ## predict target\n",
    "            log_probs = model(context_idxs)\n",
    "            ## caculate loss\n",
    "            loss = loss_criterion(log_probs, target_idx)\n",
    "            ## caculate gradients\n",
    "            loss.backward()\n",
    "            ## update weights\n",
    "            optimizer.step()\n",
    "            ## sum loss for all batches together\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "\n",
    "\n",
    "        #### Validation ####\n",
    "        ## check performance on validation set\n",
    "        model.eval()\n",
    "        ## set loss to zero again so we start fresh\n",
    "        val_loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        ## as we test on the validation set, we do not want to update our weights now\n",
    "        with torch.no_grad():\n",
    "            for context_idxs, target_idx in val_loader:\n",
    "                ## send tensors to gpu\n",
    "                context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "                log_probs = model(context_idxs)\n",
    "                ## caculate loss\n",
    "                loss = loss_criterion(log_probs, target_idx)\n",
    "                ## sum loss for whole epoch\n",
    "                val_loss_sum += loss.item()\n",
    "                \n",
    "                # Get the index of the max log-probability\n",
    "                _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "                correct += (predicted_idx == target_idx).sum().item()\n",
    "                total += context_idxs.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        ## adapt learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ## save checkpoints only if loss decreased and the epoch is larger than the patience (to save less checkpoints) but always report metrics to ray\n",
    "        if epoch > 0 and early_stopper.best_loss - config[\"min_delta\"]  > val_loss:\n",
    "          ##save checkpoint\n",
    "          torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "\n",
    "          ## report mertrics and save checkpoint\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2),\n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      },\n",
    "                  checkpoint=Checkpoint.from_directory(\".\")\n",
    "                  )\n",
    "        else:\n",
    "          ##report only metrics\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2), \n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      }\n",
    "                  )\n",
    "\n",
    "        #### Early stopping ####\n",
    "        # check if loss decreases more than defined threshold\n",
    "        early_stopper(val_loss, model)\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "\n",
    "    ## last checkpoint\n",
    "    torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "    ray.train.report(\n",
    "        {\"loss\": round(early_stopper.best_loss, 3), \"epoch\": int(epoch), \"accuracy\": round(accuracy, 3)},\n",
    "        checkpoint=Checkpoint.from_directory(\".\")\n",
    "        )\n",
    "\n",
    "    #return train_losses, val_losses, val_r2s\n",
    "    return {\n",
    "        \"loss\": round(early_stopper.best_loss, 2), \n",
    "        \"accuracy\": accuracy, \n",
    "        \"val_loss_list\": val_losses, \n",
    "        \"train_loss_list\": train_losses\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "#### Tuning ####\n",
    "## Custom function to shorten ray file path names\n",
    "def short_dirname(trial) -> str:\n",
    "    \"\"\"\n",
    "    Function that shortens path names created by Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    trial : ray.tune.Trial\n",
    "        The Ray trial object for which the directory name is being created.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    str\n",
    "        A shortened file path in the format 'trial_<trial_id>'.\n",
    "    \"\"\"\n",
    "    return \"trial_\" + str(trial.trial_id)\n",
    "\n",
    "\n",
    "## actual tuning\n",
    "def tune_parameters(training_function, num_samples, train_corpus, val_corpus, word_to_index, max_num_epochs, parameter_space, resources, local_path):\n",
    "    \"\"\"\n",
    "    Function that tunes the hyperparameters for a DL model using ASHA scheduling and saves the best model and tuning results locally.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    training_function : function\n",
    "        The function used for training the model during hyperparameter tuning.\n",
    "    num_samples : int\n",
    "        The number of hyperparameter samples to try.\n",
    "    train_dataset : object\n",
    "        Training dataset object.\n",
    "    val_dataset : object\n",
    "        Validation dataset object.\n",
    "    max_num_epochs : int\n",
    "        The maximum number of epochs for training each model.\n",
    "    parameter_space : dict\n",
    "        Dictionary defining the hyperparameter search space.\n",
    "    resources : dict\n",
    "        Resources configuration for training.\n",
    "    local_path : str\n",
    "        Local path to save tuning results and best model.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the tuning results, sorted by loss.\n",
    "        \"\"\"\n",
    "\n",
    "    ## because min number of epochs in sampling range is 50\n",
    "    #assert max_num_epochs > 50\n",
    "\n",
    "    ## Hyperparameters to sample from\n",
    "    ## ASHA scheduler to increase efficiency and stop inefficient training configs\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=3,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    ## tuning function, choose resources\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                training_function,\n",
    "                data = (train_corpus, val_corpus, word_to_index)),\n",
    "                resources= resources\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "            trial_dirname_creator=short_dirname\n",
    "        ),\n",
    "        param_space= parameter_space,\n",
    "        run_config = ray.train.RunConfig(storage_path = local_path, name=\"run_\" + datetime.now().strftime(\"%m-%d_%H_%M\"))\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "\n",
    "    #### Best Model ####\n",
    "    ## get best model\n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    ## save info about best model\n",
    "    with open(local_path + '/best_models/best_result_info_' + parameter_space[\"model\"] + '.pkl', 'wb') as file:\n",
    "        pickle.dump(best_result, file)\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"loss\"]))\n",
    "\n",
    "    ## get path to that best model\n",
    "    best_checkpoint_path = best_result.get_best_checkpoint(metric = \"loss\", mode = \"min\").path + \"/checkpoint_\"+ parameter_space[\"model\"] + \".pt\"\n",
    "    ## save path to model as txt\n",
    "    with open(local_path + f\"/best_models/path_best_model_\" + parameter_space[\"model\"] + \".txt\", \"w\") as file:\n",
    "        file.write(best_checkpoint_path)\n",
    "\n",
    "\n",
    "    #### Tuning Overview ####\n",
    "    ## Get results as df\n",
    "    df_tuning_results = results.get_dataframe()\n",
    "    ## Rename cols\n",
    "    df_tuning_results.columns = [col.replace('config/', '') for col in df_tuning_results.columns]\n",
    "    ## sort by loss\n",
    "    df_tuning_results.sort_values(\"loss\", inplace = True)\n",
    "    ## Save only relevant cols\n",
    "    df_tuning_results = df_tuning_results[['loss', \"accuracy\", \"context_size\", 'lr', 'batch_size', 'epochs',\n",
    "                                           'patience', 'min_delta', \"gamma\", \"step_size\", \n",
    "                                           \"dropout\", 'time_total_s', \"val_loss_list\", \"train_loss_list\"]]\n",
    "    ## Save as csv\n",
    "    df_tuning_results.to_csv(local_path + \"df_tuning_results.csv\")\n",
    "\n",
    "    return df_tuning_results\n",
    "\n",
    "\n",
    " #### Replication ####\n",
    "def load_best_model(model_type = str, local_path = str):\n",
    "    \"\"\"\n",
    "    Function that loads the best model based on the specified model type.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model to load (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    torch.nn.Module\n",
    "        The best pre-trained model loaded on the device and ready for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get best config\n",
    "    with open(f'{local_path}/tuning_results/best_models/best_result_info_{model_type}.pkl', 'rb') as file:\n",
    "    # Use pickle.dump() to write the data object to file\n",
    "        best_result = pickle.load(file)\n",
    "\n",
    "    with open(f\"{local_path}/tuning_results/best_models/path_best_model_{model_type}.txt\") as file:\n",
    "        path_best_file = file.read()\n",
    "\n",
    "    ## load parameters of best model\n",
    "    best_checkpoint = torch.load(path_best_file)\n",
    "\n",
    "    ## create new model\n",
    "    model_final = MLP_embeddings(\n",
    "        vocab_size = len(word_to_index), \n",
    "        embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "        )\n",
    "        \n",
    "\n",
    "    ## load parameteres of best checkpoint\n",
    "    model_final.load_state_dict(best_checkpoint)\n",
    "    ## model into evaluation mode\n",
    "    model_final.eval()\n",
    "    model_final.to(device)\n",
    "\n",
    "    return model_final\n",
    "\n",
    "\n",
    "def plot_loss_curve(model_type = str, local_path = str):\n",
    "    \n",
    "   \"\"\"\n",
    "    Function that plots the training and validation loss curves of the best model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model whose loss curve to plot (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "   ## get file with loss data\n",
    "   with open(local_path + f'/tuning_results/best_models/best_result_info_{model_type}.pkl', 'rb') as file:\n",
    "       best_result = pickle.load(file)\n",
    "\n",
    "   ## get respective tuning data\n",
    "   val_losses = best_result.metrics[\"val_loss_list\"]\n",
    "   ## i forgot to divide the train loss by n in the training function\n",
    "   ## and repeating that takes 8 hours, so I have to do it like this now\n",
    "   train_losses = best_result.metrics[\"train_loss_list\"]\n",
    "\n",
    "   ## create plot\n",
    "   plt.plot(train_losses, label='Training Loss')\n",
    "   plt.plot(val_losses, label='Validation Loss')\n",
    "   plt.title(f\"{model_type} loss curves\")\n",
    "   plt.xlabel('Epochs')\n",
    "   plt.ylabel('Loss')\n",
    "   plt.legend()\n",
    "   ## save\n",
    "   plt.savefig(local_path + f\"plots/loss_curve_{model_type}.png\")\n",
    "   plt.show()\n",
    "\n",
    "\n",
    "def classify(model_type, dataloader, index_to_word=index_to_word, include_true_vals=True):\n",
    "    model = load_best_model(model_type, local_path=local_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions, true_vals = [], []\n",
    "        for context_idx, target_idx in dataloader:\n",
    "            context_idx, target_idx = context_idx.to(device), target_idx.to(device)\n",
    "            log_probs = model(context_idx)\n",
    "\n",
    "            # Get the index of the max log-probability\n",
    "            _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "            predictions.extend([index_to_word.get(word_id.item()) for word_id in predicted_idx.cpu().numpy()])\n",
    "            \n",
    "            if include_true_vals:\n",
    "                true_vals.extend([index_to_word.get(word_id.item()) for word_id in target_idx.cpu().numpy()])\n",
    "                \n",
    "    if include_true_vals:\n",
    "        return predictions, true_vals\n",
    "    else:\n",
    "        return predictions\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_classification(model_type, prediction_val, prediction_test, y_val, y_test):\n",
    "    \"\"\"\n",
    "    Function that evaluates a classification model by computing accuracy, recall, precision, and F-score for the training and validation data, and optionally for the test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model being evaluated.\n",
    "    prediction_val : array\n",
    "        Predictions made by the model on the validation dataset.\n",
    "    prediction_test : array\n",
    "        Predictions made by the model on the test dataset.\n",
    "    y_val : array\n",
    "        Actual target values in the validation dataset.\n",
    "    y_test : array\n",
    "        Actual target values in the test dataset.\n",
    "    final_testing : bool, default=False\n",
    "        Flag indicating whether to evaluate the model on the test dataset.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"\\n--------------------------\\n{model_type} Classification Evaluation \\n--------------------------\")\n",
    "\n",
    "\n",
    "    print(\"\\nValidation set\")\n",
    "    print(\"--------------\")\n",
    "\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_val, y_pred = prediction_val, average = 'micro'):.2f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true = y_val, y_pred = prediction_val):.2f}\")\n",
    "\n",
    "    #print(classification_report(y_true = y_val, y_pred = prediction_val, digits=2, zero_division=0))\n",
    "    print(\"\\nTest set\")\n",
    "    print(\"--------\\n\")\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_test, y_pred = prediction_test, average = 'micro'):.2f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true = y_test, y_pred = prediction_test):.2f}\")\n",
    "\n",
    "    #print(classification_report(y_true = y_test, y_pred = prediction_test, digits=2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "CBOW Classification Evaluation \n",
      "--------------------------\n",
      "\n",
      "Validation set\n",
      "--------------\n",
      "F1 Score: 0.09\n",
      "Accuracy: 0.09\n",
      "\n",
      "Test set\n",
      "--------\n",
      "\n",
      "F1 Score: 0.09\n",
      "Accuracy: 0.09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "evaluate_classification(model_type = \"CBOW\", prediction_val = prediction_val, prediction_test = prediction_test, y_val = true_val, y_test = true_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val, true_val = classify(model_type=\"CBOW\", dataloader = val_loader_cbow, index_to_word=index_to_word)\n",
    "prediction_test, true_test = classify(model_type=\"CBOW\", dataloader = test_loader_cbow, index_to_word=index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n",
      "tensor([ 27, 157, 332, 257], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m---> 23\u001b[0m classify(model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBOW\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloader \u001b[38;5;241m=\u001b[39m train_loader_cbow, index_to_word\u001b[38;5;241m=\u001b[39mindex_to_word)\n",
      "Cell \u001b[1;32mIn[71], line 16\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(model_type, dataloader, index_to_word, include_true_vals)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m include_true_vals \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28mprint\u001b[39m(target_idx[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m             true_vals \u001b[38;5;241m=\u001b[39m [index_to_word\u001b[38;5;241m.\u001b[39mget(word_id\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m word_id \u001b[38;5;129;01min\u001b[39;00m target_idx\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_true_vals \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions, true_vals\n",
      "Cell \u001b[1;32mIn[71], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m include_true_vals \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28mprint\u001b[39m(target_idx[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m             true_vals \u001b[38;5;241m=\u001b[39m [index_to_word\u001b[38;5;241m.\u001b[39mget(word_id\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m word_id \u001b[38;5;129;01min\u001b[39;00m target_idx\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_true_vals \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions, true_vals\n",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "def classify(model_type, dataloader, index_to_word = index_to_word, include_true_vals = True):    \n",
    "    model = load_best_model(model_type, local_path = local_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for target_idx, context_idx in dataloader:\n",
    "            target_idx, context_idx = target_idx.to(device), context_idx.to(device)\n",
    "            log_probs = model(target_idx)\n",
    "\n",
    "            # Get the index of the max log-probability\n",
    "            _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "            predictions = [index_to_word.get(word_id.item()) for word_id in predicted_idx.cpu().numpy()]\n",
    "            \n",
    "            if include_true_vals == True:\n",
    "                true_vals = [index_to_word.get(word_id.item()) for word_id in target_idx.cpu().numpy()]\n",
    "    if include_true_vals == True:\n",
    "        return predictions, true_vals\n",
    "    else:\n",
    "        return predictions\n",
    "\n",
    "\n",
    "classify(model_type=\"CBOW\", dataloader = train_loader_cbow, index_to_word=index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation classification results\n",
    "def evaluate_classification(model_type, dataloader_train, dataloader_val, dataloader_test):\n",
    "    \"\"\"\n",
    "    Function that evaluates a classification model by computing accuracy, recall, precision, and F-score for the training and validation data, and optionally for the test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model being evaluated.\n",
    "    prediction_val : array\n",
    "        Predictions made by the model on the validation dataset.\n",
    "    prediction_test : array\n",
    "        Predictions made by the model on the test dataset.\n",
    "    y_val : array\n",
    "        Actual target values in the validation dataset.\n",
    "    y_test : array\n",
    "        Actual target values in the test dataset.\n",
    "    final_testing : bool, default=False\n",
    "        Flag indicating whether to evaluate the model on the test dataset.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    ## label emotions\n",
    "    y_val = [emotion_dict.get(emotion_int) for emotion_int in y_val]\n",
    "    y_test = [emotion_dict.get(emotion_int) for emotion_int in y_test]\n",
    "\n",
    "    print(f\"\\n--------------------------\\n{model_type} Classification Evaluation \\n--------------------------\")\n",
    "\n",
    "\n",
    "    print(\"\\nValidation set\")\n",
    "    print(\"--------------\")\n",
    "\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_val, y_pred = prediction_val, average = 'micro'):.2f}\")\n",
    "\n",
    "    #print(classification_report(y_true = y_val, y_pred = prediction_val, digits=2, zero_division=0))\n",
    "\n",
    "    print(\"\\nTest set\")\n",
    "    print(\"--------\\n\")\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_test, y_pred = prediction_test, average = 'micro'):.2f}\")\n",
    "    print(classification_report(y_true = y_test, y_pred = prediction_test, digits=2, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'the',\n",
       " 'that',\n",
       " 'of',\n",
       " 'the',\n",
       " 'the',\n",
       " 'to',\n",
       " 'the',\n",
       " 'the',\n",
       " 'to',\n",
       " 'the',\n",
       " 'change',\n",
       " 'change',\n",
       " 'the',\n",
       " 'change',\n",
       " 'change',\n",
       " 'be',\n",
       " 'the',\n",
       " 'be',\n",
       " 'be',\n",
       " 'be',\n",
       " 'be',\n",
       " 'be',\n",
       " 'be',\n",
       " 'the',\n",
       " 'change',\n",
       " 'change',\n",
       " 'the']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get data\n",
    "comments = pd.read_csv(local_path +\"data/preprocessed/comments.csv\")\n",
    "\n",
    "# Splitting the data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(comments, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "#Adding all comments for generating the vocabulary. If not an error occurs when tokens missing\n",
    "total_comments_list = comments[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "\n",
    "train_list = train_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "val_list = val_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "test_list = test_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "\n",
    "# Ensure each entry is a string and split each sentence into words\n",
    "total_corpus = [doc.split() for doc in total_comments_list]\n",
    "corpus_train = [doc.split() for doc in train_list]\n",
    "corpus_val = [doc.split() for doc in val_list]\n",
    "corpus_test = [doc.split() for doc in test_list]\n",
    "\n",
    "# Create a vocabulary: count occurrences of each word\n",
    "vocab = defaultdict(int)\n",
    "for sentence in total_corpus:\n",
    "    for word in sentence:\n",
    "        vocab[word] += 1\n",
    "\n",
    "# Remove infrequent words from the vocabulary\n",
    "min_count = 6\n",
    "vocab = {word: count for word, count in vocab.items() if count >= min_count}\n",
    "\n",
    "# Create word to index and index to word mappings\n",
    "word_to_index = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "# Create DataFrame from vocabulary\n",
    "vocab_df = pd.DataFrame(list(vocab.items()), columns=['Word', 'Count'])\n",
    "\n",
    "vocab_set = set(vocab.keys())\n",
    "\n",
    "def filter_corpus(corpus, vocab_set):\n",
    "    return [[word for word in doc if word in vocab_set] for doc in corpus]\n",
    "\n",
    "filtered_total_corpus = filter_corpus(total_corpus, vocab_set)\n",
    "filtered_corpus_train = filter_corpus(corpus_train, vocab_set)\n",
    "filtered_corpus_val = filter_corpus(corpus_val, vocab_set)\n",
    "filtered_corpus_test = filter_corpus(corpus_test, vocab_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pairs_skip = create_context_target_pairs_skipgram(corpus_train, context_size)\n",
    "#val_pairs_skip = create_context_target_pairs_skipgram(corpus_val, context_size)\n",
    "#test_pairs_skip = create_context_target_pairs_skipgram(corpus_test, context_size)\n",
    "#\n",
    "#train_dataset_skip = Word2VecDataset(train_pairs_skip, word_to_index)\n",
    "#val_dataset_skip = Word2VecDataset(val_pairs_skip, word_to_index)\n",
    "#test_dataset_skip = Word2VecDataset(test_pairs_skip, word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## use the gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#### Continuous bag of words model #####\n",
    "class MLP_embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(MLP_embeddings, self).__init__()\n",
    "        # Embedding layer for word indices\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Linear layer for mapping embeddings to vocab size\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # Get embeddings for context words\n",
    "        embeds = self.embeddings(context)\n",
    "        # Average embeddings to get a single vector\n",
    "        combined = torch.mean(embeds, dim=1)\n",
    "        # Apply dropout and pass through linear layer\n",
    "        out = self.linear1(self.dropout(combined))\n",
    "        # Compute log probabilities\n",
    "        log_probs = torch.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tuning ####\n",
    "## choose sample size and max epoch\n",
    "n_samples = 2\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-09 10:01:01</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:35.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.4/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 6.000: -6.415 | Iter 3.000: -7.09<br>Logical resource usage: 2.0/8 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:GTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  context_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  min_delta</th><th style=\"text-align: right;\">  patience</th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_4bc01_00000</td><td>TERMINATED</td><td>127.0.0.1:12036</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">             3</td><td style=\"text-align: right;\"> 0.440698</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">     190</td><td style=\"text-align: right;\">    0.9</td><td style=\"text-align: right;\">0.000149258</td><td style=\"text-align: right;\">0.000120387</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">   0.000208872</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         85.2612</td><td style=\"text-align: right;\">  6.22</td><td style=\"text-align: right;\"> 0.0807492</td></tr>\n",
       "<tr><td>train_model_4bc01_00001</td><td>TERMINATED</td><td>127.0.0.1:532  </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">             4</td><td style=\"text-align: right;\"> 0.209602</td><td style=\"text-align: right;\">            500</td><td style=\"text-align: right;\">     140</td><td style=\"text-align: right;\">    0.9</td><td style=\"text-align: right;\">0.00011084 </td><td style=\"text-align: right;\">0.00181241 </td><td style=\"text-align: right;\">         5</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.000679754</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         64.0774</td><td style=\"text-align: right;\">  6.46</td><td style=\"text-align: right;\"> 0.0722685</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000000)\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000001)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000002)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000003)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=532)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00001/checkpoint_000003)\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000004)\n",
      "\u001b[36m(train_model pid=532)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00001/checkpoint_000004)\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000005)\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000006)\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000007)\n",
      "2024-08-09 10:01:01,394\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-08-09 10:01:01,401\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to 'd:/dlss-project24/tuning_results/run_08-09_09_59' in 0.0229s.\n",
      "2024-08-09 10:01:01,418\tINFO tune.py:1039 -- Total run time: 95.81 seconds (95.72 seconds for the tuning loop).\n",
      "\u001b[36m(train_model pid=12036)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-09_09_59/trial_4bc01_00000/checkpoint_000008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'model': 'CBOW', 'context_size': 3, 'dropout': 0.4406984524960214, 'lr': 0.00014925798182534972, 'batch_size': 256, 'epochs': 190, 'patience': 10, 'min_delta': 0.00012038740121861965, 'gamma': 0.9, 'step_size': 10, 'weight_decay': 0.0002088717192918404, 'embedding_dim': 100}\n",
      "Best trial final validation loss: 6.22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>context_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patience</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>step_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>val_loss_list</th>\n",
       "      <th>train_loss_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.22</td>\n",
       "      <td>0.080749</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>256</td>\n",
       "      <td>190</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.440698</td>\n",
       "      <td>85.261245</td>\n",
       "      <td>[7.621071794576812, 7.195064845838044, 6.74439...</td>\n",
       "      <td>[7.823443503940807, 7.420753813841763, 6.95406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.46</td>\n",
       "      <td>0.072268</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>512</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.209602</td>\n",
       "      <td>64.077419</td>\n",
       "      <td>[7.38247276203973, 6.9791763084275384, 6.70361...</td>\n",
       "      <td>[7.66037266620536, 7.161159822556856, 6.795258...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy  context_size        lr  batch_size  epochs  patience  \\\n",
       "0  6.22  0.080749             3  0.000149         256     190        10   \n",
       "1  6.46  0.072268             4  0.000111         512     140         5   \n",
       "\n",
       "   min_delta  gamma  step_size   dropout  time_total_s  \\\n",
       "0   0.000120    0.9         10  0.440698     85.261245   \n",
       "1   0.001812    0.9          5  0.209602     64.077419   \n",
       "\n",
       "                                       val_loss_list  \\\n",
       "0  [7.621071794576812, 7.195064845838044, 6.74439...   \n",
       "1  [7.38247276203973, 6.9791763084275384, 6.70361...   \n",
       "\n",
       "                                     train_loss_list  \n",
       "0  [7.823443503940807, 7.420753813841763, 6.95406...  \n",
       "1  [7.66037266620536, 7.161159822556856, 6.795258...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    train_corpus = filtered_corpus_train,\n",
    "    val_corpus = filtered_corpus_val,\n",
    "    word_to_index= word_to_index,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1/2},\n",
    "    parameter_space = {\n",
    "            \"model\": \"CBOW\",\n",
    "            \"context_size\": tune.choice([2, 3, 4, 5]),\n",
    "            \"dropout\": tune.loguniform(0.1, 0.5),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([32, 64, 128, 256, 512, 1024]),\n",
    "            \"epochs\": tune.choice(list(range(50, 200, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([50, 100, 250, 500, 750, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curve(\"CBOW\", local_path = local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions = classify(model_type = \"CBOW\", dataloader = test_loader_cbow,index_to_word = index_to_word)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 2\n",
    "batch_size = 64\n",
    "\n",
    "train_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_train, context_size)\n",
    "val_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_val, context_size)\n",
    "test_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_test, context_size)\n",
    "\n",
    "train_dataset_cbow = Word2VecDataset(train_pairs_cbow, word_to_index)\n",
    "val_dataset_cbow = Word2VecDataset(val_pairs_cbow, word_to_index)\n",
    "test_dataset_cbow = Word2VecDataset(test_pairs_cbow, word_to_index)\n",
    "\n",
    "train_loader_cbow = DataLoader(train_dataset_cbow, batch_size=batch_size, shuffle=True, generator = torch.Generator().manual_seed(1234))\n",
    "val_loader_cbow = DataLoader(val_dataset_cbow, batch_size=batch_size, shuffle=False)\n",
    "test_loader_cbow = DataLoader(test_dataset_cbow, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluate on validation and test datasets\n",
    "val_loss, val_accuracy = evaluate_model(\"CBOW\", val_loader_cbow)\n",
    "test_loss, test_accuracy = evaluate_model(\"CBOW\", test_loader_cbow)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.2f}, Validation Accuracy: {val_accuracy:.2f}\")\n",
    "print(f\"Test Loss: {test_loss:.2f}, Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model,\n",
    "    num_samples=n_samples,\n",
    "    train_dataset = train_dataset_skip,\n",
    "    val_dataset = val_dataset_skip,\n",
    "    vocab_size= vocab_size,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1/2},\n",
    "    parameter_space = {\n",
    "            \"model\": \"skipgram\",\n",
    "            \"dropout\": tune.loguniform(0.1, 0.5),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "            \"epochs\": tune.choice(list(range(50, 200, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([50, 100, 250, 500, 750, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(\"skipgram\", local_path = local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_best_model(\"skipgram\", local_path = local_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
