{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab:\n",
    "If you run this code in colab, execute the following code  each time you have a fresh session.\n",
    "\n",
    "This is necessary due to some package dependencies of ray.\n",
    "\n",
    "You also need to habe a folder \"DLSS\" in your drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    ## this is necessary to get ray running on colab\n",
    "    !pip uninstall -y -q pyarrow\n",
    "    !pip install pyarrow==14.0.1\n",
    "    !pip install -q -U ray[tune]\n",
    "    !pip install -q ray[debug]\n",
    "    ## force crash as restart is necessary due to the installed packages\n",
    "    import os\n",
    "    os._exit(0)\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  d:\\dlss-project24/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dlss-project24\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-16 22:56:54,761\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-08-16 22:56:56,033\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "## check if on colab\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "    local_path = \"/content/drive/MyDrive/DLSS/\"\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "    ## get current directory\n",
    "    current_wd = os.getcwd()\n",
    "    ## move one up to go to main directory\n",
    "    local_path = os.path.dirname(current_wd) + \"/\"\n",
    "\n",
    "print(\"CWD: \", local_path)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import Checkpoint\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from datetime import datetime\n",
    "import os \n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_corpus(corpus, vocab_set):\n",
    "    return [[word for word in doc if word in vocab_set] for doc in corpus]\n",
    "\n",
    "# Function to create context-target pairs\n",
    "def create_context_target_pairs_cbow(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(context_size, len(sentence) - context_size):\n",
    "            context = sentence[i - context_size:i] + sentence[i + 1:i + context_size + 1]\n",
    "            target = sentence[i]\n",
    "            pairs.append((context, target))\n",
    "    return pairs\n",
    "\n",
    "# Function to create context-target pairs for Skip-gram\n",
    "def create_context_target_pairs_skipgram(text, context_size):\n",
    "    pairs = []\n",
    "    for sentence in text:\n",
    "        for i in range(len(sentence)):\n",
    "            target = sentence[i]\n",
    "            context = sentence[max(0, i - context_size):i] + sentence[i + 1:i + context_size + 1]\n",
    "            for ctx in context:\n",
    "                pairs.append((target, ctx))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# Dataset and DataLoader definition\n",
    "class Word2VecDataset_cbow(Dataset):\n",
    "    def __init__(self, pairs, word_to_index):\n",
    "        self.pairs = pairs\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.pairs[idx]\n",
    "        context_idxs = torch.tensor([self.word_to_index[word] for word in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor(self.word_to_index[target], dtype=torch.long)\n",
    "        return context_idxs, target_idx\n",
    "  \n",
    "class Word2VecDataset_skipgram(Dataset):\n",
    "    def __init__(self, pairs, word_to_index):\n",
    "        self.pairs = pairs\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, context = self.pairs[idx]\n",
    "        target_idx = torch.tensor(self.word_to_index[target], dtype=torch.long)\n",
    "        context_idx = torch.tensor(self.word_to_index[context], dtype=torch.long)\n",
    "        return target_idx, context_idx  \n",
    "\n",
    "def prepare_data_for_model_training(file_name = \"str\", min_count = int, data_sample_name = str):\n",
    "    #### Parameters to choose:\n",
    "    ## get data\n",
    "    comments = pd.read_csv(local_path +f\"/data/preprocessed/{file_name}.csv\")\n",
    "\n",
    "    # Splitting the data into train, validation, and test sets\n",
    "    train_df, temp_df = train_test_split(comments, test_size=0.3, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    #Adding all comments for generating the vocabulary. If not an error occurs when tokens missing\n",
    "    total_comments_list = comments[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "\n",
    "    train_list = train_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "    val_list = val_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "    test_list = test_df[\"lemmatized\"].dropna().astype(str).tolist()\n",
    "\n",
    "    # Ensure each entry is a string and split each sentence into words\n",
    "    total_corpus = [doc.split() for doc in total_comments_list]\n",
    "    corpus_train = [doc.split() for doc in train_list]\n",
    "    corpus_val = [doc.split() for doc in val_list]\n",
    "    corpus_test = [doc.split() for doc in test_list]\n",
    "\n",
    "    # Create a vocabulary: count occurrences of each word\n",
    "    vocab = defaultdict(int)\n",
    "    for sentence in total_corpus:\n",
    "        for word in sentence:\n",
    "            vocab[word] += 1\n",
    "\n",
    "    # Remove infrequent words from the vocabulary\n",
    "    vocab = {word: count for word, count in vocab.items() if count >= min_count}\n",
    "\n",
    "    # Create word to index and index to word mappings\n",
    "    word_to_index = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
    "    index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "    # Create DataFrame from vocabulary\n",
    "    vocab_df = pd.DataFrame(list(vocab.items()), columns=['Word', 'Count'])\n",
    "\n",
    "    vocab_set = set(vocab.keys())\n",
    "\n",
    "    filtered_total_corpus = filter_corpus(total_corpus, vocab_set)\n",
    "    filtered_corpus_train = filter_corpus(corpus_train, vocab_set)\n",
    "    filtered_corpus_val = filter_corpus(corpus_val, vocab_set)\n",
    "    filtered_corpus_test = filter_corpus(corpus_test, vocab_set)\n",
    "    return filtered_corpus_train, filtered_corpus_val, filtered_corpus_test, word_to_index, index_to_word, data_sample_name\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Class that implements early stopping to halt training when the validation loss stops improving.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "\n",
    "    Methods:\n",
    "    ----------\n",
    "    __call__(val_loss, model)\n",
    "        Checks if the validation loss has improved and updates the state of early stopping.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    patience : int\n",
    "        Number of epochs to wait after the last improvement in validation loss before stopping the training.\n",
    "    min_delta : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "    counter : int\n",
    "        Counter for the number of epochs since the last improvement.\n",
    "    best_loss : float or None\n",
    "        Best recorded validation loss.\n",
    "    early_stop : bool\n",
    "        Indicating whether training should be stopped early.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience= int, min_delta= float):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        ## for the first training iteration\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            ## check if the loss decreased, if not:\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            ## if loss decrease (more than the defined delta): save model parameters, reset counter and update best loss\n",
    "        else:\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "\n",
    "\n",
    "def train_model_cbow(config, data):\n",
    "    \"\"\"\n",
    "    Function that trains a model using the specified configuration and data, implements early stopping based on validation loss improvement, and reports training progress and results to Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    config : dict\n",
    "        Dictionary containing hyperparameters and settings for the model, training, and early stopping.\n",
    "    data : tuple\n",
    "        Tuple containing training and validation datasets.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dict\n",
    "        A dictionary containing the final training loss, validation loss, accuracy, the epoch at which training stopped,\n",
    "        and lists of validation and training losses across epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    filtered_corpus_train, filtered_corpus_val, word_to_index = data\n",
    "    \n",
    "    train_pairs = create_context_target_pairs_cbow(filtered_corpus_train, config[\"context_size\"])\n",
    "    val_pairs = create_context_target_pairs_cbow(filtered_corpus_val, config[\"context_size\"])\n",
    "    train_dataset = Word2VecDataset_cbow(train_pairs, word_to_index)\n",
    "    val_dataset = Word2VecDataset_cbow(val_pairs, word_to_index)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, generator = torch.Generator().manual_seed(1234))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    \n",
    "    ## set seed to replicate the model\n",
    "    torch.manual_seed(1234)\n",
    "\n",
    "    ## empty lists to store loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    ## initialise model\n",
    "    model = CBOW(len(word_to_index), config[\"embedding_dim\"]).to(device)\n",
    "        \n",
    "    ## loss criterion\n",
    "    loss_criterion = nn.NLLLoss()\n",
    "\n",
    "    ## choose optimiser\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    ## adapt learning rate with scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "\n",
    "    #### Early Stopper ####\n",
    "    early_stopper = EarlyStopping(patience= config[\"patience\"], min_delta = config[\"min_delta\"])\n",
    "\n",
    "    #### Training ####\n",
    "    ## each epoch iterates through the whole dataset\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        ## train model on training set\n",
    "        model.train()\n",
    "        ## set loss and r2 to zero again so we start fresh\n",
    "        train_loss = 0\n",
    "        ## iterate through batches of the training data (data is the features and target the target)\n",
    "        for context_idxs, target_idx in train_loader:\n",
    "            ## send tensors to gpu\n",
    "            context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "            ## reset gradient to 0,start fresh again\n",
    "            optimizer.zero_grad()\n",
    "            ## predict target\n",
    "            log_probs = model(context_idxs)\n",
    "            ## caculate loss\n",
    "            loss = loss_criterion(log_probs, target_idx)\n",
    "            ## caculate gradients\n",
    "            loss.backward()\n",
    "            ## update weights\n",
    "            optimizer.step()\n",
    "            ## sum loss for all batches together\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "\n",
    "\n",
    "        #### Validation ####\n",
    "        ## check performance on validation set\n",
    "        model.eval()\n",
    "        ## set loss to zero again so we start fresh\n",
    "        val_loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        ## as we test on the validation set, we do not want to update our weights now\n",
    "        with torch.no_grad():\n",
    "            for context_idxs, target_idx in val_loader:\n",
    "                ## send tensors to gpu\n",
    "                context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "                log_probs = model(context_idxs)\n",
    "                ## caculate loss\n",
    "                loss = loss_criterion(log_probs, target_idx)\n",
    "                ## sum loss for whole epoch\n",
    "                val_loss_sum += loss.item()\n",
    "                \n",
    "                # Get the index of the max log-probability\n",
    "                _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "                correct += (predicted_idx == target_idx).sum().item()\n",
    "                total += context_idxs.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        ## adapt learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ## save checkpoints only if loss decreased and the epoch is larger than the patience (to save less checkpoints) but always report metrics to ray\n",
    "        if epoch > 0 and early_stopper.best_loss - config[\"min_delta\"]  > val_loss:\n",
    "          ##save checkpoint\n",
    "          torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "\n",
    "          ## report mertrics and save checkpoint\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2),\n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      },\n",
    "                  checkpoint=Checkpoint.from_directory(\".\")\n",
    "                  )\n",
    "        else:\n",
    "          ##report only metrics\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2), \n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      }\n",
    "                  )\n",
    "\n",
    "        #### Early stopping ####\n",
    "        # check if loss decreases more than defined threshold\n",
    "        early_stopper(val_loss, model)\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "\n",
    "    ## last checkpoint\n",
    "    torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "    ray.train.report(\n",
    "        {\"loss\": round(early_stopper.best_loss, 3), \"epoch\": int(epoch), \"accuracy\": round(accuracy, 3)},\n",
    "        checkpoint=Checkpoint.from_directory(\".\")\n",
    "        )\n",
    "\n",
    "    #return train_losses, val_losses, val_r2s\n",
    "    return {\n",
    "        \"loss\": round(early_stopper.best_loss, 2), \n",
    "        \"accuracy\": accuracy, \n",
    "        \"val_loss_list\": val_losses, \n",
    "        \"train_loss_list\": train_losses\n",
    "        }\n",
    "\n",
    "def train_model_skipgram(config, data):\n",
    "    \"\"\"\n",
    "    Function that trains a model using the specified configuration and data, implements early stopping based on validation loss improvement, and reports training progress and results to Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    config : dict\n",
    "        Dictionary containing hyperparameters and settings for the model, training, and early stopping.\n",
    "    data : tuple\n",
    "        Tuple containing training and validation datasets.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dict\n",
    "        A dictionary containing the final training loss, validation loss, accuracy, the epoch at which training stopped,\n",
    "        and lists of validation and training losses across epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    filtered_corpus_train, filtered_corpus_val, word_to_index = data\n",
    "\n",
    "    train_pairs = create_context_target_pairs_skipgram(filtered_corpus_train, config[\"context_size\"])\n",
    "    val_pairs = create_context_target_pairs_skipgram(filtered_corpus_val, config[\"context_size\"])\n",
    "    train_dataset = Word2VecDataset_skipgram(train_pairs, word_to_index)\n",
    "    val_dataset = Word2VecDataset_skipgram(val_pairs, word_to_index)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, generator = torch.Generator().manual_seed(1234))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    \n",
    "    ## set seed to replicate the model\n",
    "    torch.manual_seed(1234)\n",
    "\n",
    "    ## empty lists to store loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    ## initialise model\n",
    "    model = SkipGram(len(word_to_index), config[\"embedding_dim\"]).to(device)\n",
    "        \n",
    "    ## loss criterion\n",
    "    loss_criterion = nn.NLLLoss()\n",
    "\n",
    "    ## choose optimiser\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    ## adapt learning rate with scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "\n",
    "    #### Early Stopper ####\n",
    "    early_stopper = EarlyStopping(patience= config[\"patience\"], min_delta = config[\"min_delta\"])\n",
    "\n",
    "    #### Training ####\n",
    "    ## each epoch iterates through the whole dataset\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        ## train model on training set\n",
    "        model.train()\n",
    "        ## set loss and r2 to zero again so we start fresh\n",
    "        train_loss = 0\n",
    "        ## iterate through batches of the training data (data is the features and target the target)\n",
    "        for context_idxs, target_idx in train_loader:\n",
    "            ## send tensors to gpu\n",
    "            context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "            ## reset gradient to 0,start fresh again\n",
    "            optimizer.zero_grad()\n",
    "            ## predict target\n",
    "            log_probs = model(target_idx)\n",
    "            ## caculate loss\n",
    "            loss = loss_criterion(log_probs, context_idxs)\n",
    "            ## caculate gradients\n",
    "            loss.backward()\n",
    "            ## update weights\n",
    "            optimizer.step()\n",
    "            ## sum loss for all batches together\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "\n",
    "\n",
    "        #### Validation ####\n",
    "        ## check performance on validation set\n",
    "        model.eval()\n",
    "        ## set loss to zero again so we start fresh\n",
    "        val_loss_sum = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        ## as we test on the validation set, we do not want to update our weights now\n",
    "        with torch.no_grad():\n",
    "            for context_idxs, target_idx in val_loader:\n",
    "                ## send tensors to gpu\n",
    "                context_idxs, target_idx = context_idxs.to(device), target_idx.to(device)\n",
    "                log_probs = model(target_idx)\n",
    "                ## caculate loss\n",
    "                loss = loss_criterion(log_probs, context_idxs)\n",
    "                ## sum loss for whole epoch\n",
    "                val_loss_sum += loss.item()\n",
    "                \n",
    "                # Get the index of the max log-probability\n",
    "                _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "                correct += (predicted_idx == context_idxs).sum().item()\n",
    "                total += context_idxs.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader)\n",
    "        accuracy = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        ## adapt learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ## save checkpoints only if loss decreased and the epoch is larger than the patience (to save less checkpoints) but always report metrics to ray\n",
    "        if epoch > 0 and early_stopper.best_loss - config[\"min_delta\"]  > val_loss:\n",
    "          ##save checkpoint\n",
    "          torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "\n",
    "          ## report mertrics and save checkpoint\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2),\n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      },\n",
    "                  checkpoint=Checkpoint.from_directory(\".\")\n",
    "                  )\n",
    "        else:\n",
    "          ##report only metrics\n",
    "          ray.train.report(\n",
    "                  {\n",
    "                      \"loss\": round(early_stopper.best_loss, 2), \n",
    "                      \"val_loss_list\": val_losses,\n",
    "                      \"train_loss_list\": train_losses,\n",
    "                      \"accuracy\": accuracy\n",
    "                      }\n",
    "                  )\n",
    "\n",
    "        #### Early stopping ####\n",
    "        # check if loss decreases more than defined threshold\n",
    "        early_stopper(val_loss, model)\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "\n",
    "    ## last checkpoint\n",
    "    torch.save(model.state_dict(), \"checkpoint_\" + config[\"model\"] + \".pt\")\n",
    "    ray.train.report(\n",
    "        {\"loss\": round(early_stopper.best_loss, 3), \"epoch\": int(epoch), \"accuracy\": round(accuracy, 3)},\n",
    "        checkpoint=Checkpoint.from_directory(\".\")\n",
    "        )\n",
    "\n",
    "    #return train_losses, val_losses, val_r2s\n",
    "    return {\n",
    "        \"loss\": round(early_stopper.best_loss, 2), \n",
    "        \"accuracy\": accuracy, \n",
    "        \"val_loss_list\": val_losses, \n",
    "        \"train_loss_list\": train_losses\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "#### Tuning ####\n",
    "## Custom function to shorten ray file path names\n",
    "def short_dirname(trial) -> str:\n",
    "    \"\"\"\n",
    "    Function that shortens path names created by Ray.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    trial : ray.tune.Trial\n",
    "        The Ray trial object for which the directory name is being created.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    str\n",
    "        A shortened file path in the format 'trial_<trial_id>'.\n",
    "    \"\"\"\n",
    "    return \"trial_\" + str(trial.trial_id)\n",
    "\n",
    "\n",
    "## actual tuning\n",
    "def tune_parameters(training_function, num_samples, train_corpus, val_corpus, word_to_index, max_num_epochs, parameter_space, resources, local_path):\n",
    "    \"\"\"\n",
    "    Function that tunes the hyperparameters for a DL model using ASHA scheduling and saves the best model and tuning results locally.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    training_function : function\n",
    "        The function used for training the model during hyperparameter tuning.\n",
    "    num_samples : int\n",
    "        The number of hyperparameter samples to try.\n",
    "    train_dataset : object\n",
    "        Training dataset object.\n",
    "    val_dataset : object\n",
    "        Validation dataset object.\n",
    "    max_num_epochs : int\n",
    "        The maximum number of epochs for training each model.\n",
    "    parameter_space : dict\n",
    "        Dictionary defining the hyperparameter search space.\n",
    "    resources : dict\n",
    "        Resources configuration for training.\n",
    "    local_path : str\n",
    "        Local path to save tuning results and best model.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the tuning results, sorted by loss.\n",
    "        \"\"\"\n",
    "\n",
    "    ## because min number of epochs in sampling range is 50\n",
    "    #assert max_num_epochs > 50\n",
    "\n",
    "    ## Hyperparameters to sample from\n",
    "    ## ASHA scheduler to increase efficiency and stop inefficient training configs\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=3,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    ## tuning function, choose resources\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                training_function,\n",
    "                data = (train_corpus, val_corpus, word_to_index)),\n",
    "                resources= resources\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "            trial_dirname_creator=short_dirname\n",
    "        ),\n",
    "        param_space= parameter_space,\n",
    "        run_config = ray.train.RunConfig(storage_path = local_path, name=\"run_\" + datetime.now().strftime(\"%m-%d_%H_%M\"))\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "\n",
    "    #### Best Model ####\n",
    "    \n",
    "    ## create folder\n",
    "    os.makedirs(local_path + f'/best_models_{parameter_space[\"data_sample_name\"]}', exist_ok=True)\n",
    "    \n",
    "    ## get best model\n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    ## save info about best model\n",
    "    with open(local_path + f'/best_models_{parameter_space[\"data_sample_name\"]}/best_result_info_' + parameter_space[\"model\"] + '.pkl', 'wb') as file:\n",
    "        pickle.dump(best_result, file)\n",
    "        \n",
    "        \n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"loss\"]))\n",
    "\n",
    "    ## get path to that best model\n",
    "    best_checkpoint_path = best_result.get_best_checkpoint(metric = \"loss\", mode = \"min\").path + \"/checkpoint_\"+ parameter_space[\"model\"] + \".pt\"\n",
    "    ## save path to model as txt\n",
    "    #with open(local_path + f\"/best_models_{parameter_space[\"folder_ending\"]}//path_best_model_\" + parameter_space[\"model\"] + \".txt\", \"w\") as file:\n",
    "    #    file.write(best_checkpoint_path)\n",
    "\n",
    "    ##save model parameters\n",
    "    best_checkpoint = torch.load(best_checkpoint_path)\n",
    "    \n",
    "    ## create new model\n",
    "    if parameter_space[\"model\"] == \"CBOW\":\n",
    "        model_final = CBOW(\n",
    "            vocab_size = len(word_to_index), \n",
    "            embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "            )\n",
    "    else:\n",
    "        model_final = SkipGram(\n",
    "            vocab_size = len(word_to_index), \n",
    "            embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "            )\n",
    "        \n",
    "        \n",
    "\n",
    "    ## load parameteres of best checkpoint\n",
    "    model_final.load_state_dict(best_checkpoint)    \n",
    "    \n",
    "    torch.save(model_final.state_dict(), local_path + f'/best_models_{parameter_space[\"data_sample_name\"]}/best_model_parameters_' + parameter_space[\"model\"] + '.pt')\n",
    "    \n",
    "    #### Tuning Overview ####\n",
    "    ## Get results as df\n",
    "    df_tuning_results = results.get_dataframe()\n",
    "    ## Rename cols\n",
    "    df_tuning_results.columns = [col.replace('config/', '') for col in df_tuning_results.columns]\n",
    "    ## sort by loss\n",
    "    df_tuning_results.sort_values(\"loss\", inplace = True)\n",
    "    ## Save only relevant cols\n",
    "    df_tuning_results = df_tuning_results[['loss', \"accuracy\", \"context_size\", 'lr', 'batch_size', 'epochs',\n",
    "                                           'patience', 'min_delta', \"gamma\", \"step_size\", \n",
    "                                           \"dropout\", 'time_total_s', \"val_loss_list\", \"train_loss_list\"]]\n",
    "    ## Save as csv\n",
    "    df_tuning_results.to_csv(local_path + f'/best_models_{parameter_space[\"data_sample_name\"]}/df_tuning_results' + parameter_space[\"model\"] + '.csv')\n",
    "\n",
    "    return df_tuning_results\n",
    "\n",
    "\n",
    " #### Replication ####\n",
    "def load_best_model(model_type = str, local_path = str, data_sample_name = str):\n",
    "    \"\"\"\n",
    "    Function that loads the best model based on the specified model type.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model to load (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    torch.nn.Module\n",
    "        The best pre-trained model loaded on the device and ready for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get best config\n",
    "    with open(f'{local_path}/tuning_results/best_models_{data_sample_name}/best_result_info_{model_type}.pkl', 'rb') as file:\n",
    "    # Use pickle.dump() to write the data object to file\n",
    "        best_result = pickle.load(file)\n",
    "\n",
    "    #with open(f\"{local_path}/tuning_results/best_models/path_best_model_{model_type}.txt\") as file:\n",
    "    #    path_best_file = file.read()\n",
    "\n",
    "    ## load parameters of best model\n",
    "    best_checkpoint = torch.load(f'{local_path}/tuning_results/best_models_{data_sample_name}/best_model_parameters_{model_type}.pt')\n",
    "\n",
    "    ## create new model\n",
    "    if model_type == \"CBOW\":\n",
    "        model_final = CBOW(\n",
    "            vocab_size = len(word_to_index), \n",
    "            embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "            )\n",
    "    else:\n",
    "        model_final = SkipGram(\n",
    "            vocab_size = len(word_to_index), \n",
    "            embedding_dim = best_result.metrics[\"config\"][\"embedding_dim\"]\n",
    "            )\n",
    "        \n",
    "        \n",
    "\n",
    "    ## load parameteres of best checkpoint\n",
    "    model_final.load_state_dict(best_checkpoint)\n",
    "    ## model into evaluation mode\n",
    "    model_final.eval()\n",
    "    model_final.to(device)\n",
    "\n",
    "    return model_final\n",
    "\n",
    "\n",
    "def plot_loss_curve(model_type = str, local_path = str, data_sample_name = str):\n",
    "    \n",
    "   \"\"\"\n",
    "    Function that plots the training and validation loss curves of the best model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model whose loss curve to plot (\"CNN\" or other).\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "   ## get file with loss data\n",
    "   with open(local_path + f\"/tuning_results/best_models_{data_sample_name}/best_result_info_{model_type}.pkl\", 'rb') as file:\n",
    "       best_result = pickle.load(file)\n",
    "\n",
    "   ## get respective tuning data\n",
    "   val_losses = best_result.metrics[\"val_loss_list\"]\n",
    "   ## i forgot to divide the train loss by n in the training function\n",
    "   ## and repeating that takes 8 hours, so I have to do it like this now\n",
    "   train_losses = best_result.metrics[\"train_loss_list\"]\n",
    "\n",
    "   ## create plot\n",
    "   plt.plot(train_losses, label='Training Loss')\n",
    "   plt.plot(val_losses, label='Validation Loss')\n",
    "   plt.title(f\"{model_type} loss curves\")\n",
    "   plt.xlabel('Epochs')\n",
    "   plt.ylabel('Loss')\n",
    "   plt.legend()\n",
    "   ## save\n",
    "   plt.savefig(local_path + f\"plots/loss_curve_{model_type}_{data_sample_name}.png\")\n",
    "   plt.show()\n",
    "\n",
    "\n",
    "def classify(model_type, dataloader, index_to_word, data_sample_name = str, include_true_vals=True):\n",
    "    model = load_best_model(model_type, local_path=local_path, data_sample_name = data_sample_name)\n",
    "\n",
    "    if model_type == \"CBOW\":\n",
    "        with torch.no_grad():\n",
    "            predictions, true_vals = [], []\n",
    "            for context_idx, target_idx in dataloader:\n",
    "                context_idx, target_idx = context_idx.to(device), target_idx.to(device)\n",
    "                log_probs = model(context_idx)\n",
    "\n",
    "                # Get the index of the max log-probability\n",
    "                _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "                predictions.extend([index_to_word.get(word_id.item()) for word_id in predicted_idx.cpu().numpy()])\n",
    "                \n",
    "                if include_true_vals:\n",
    "                    true_vals.extend([index_to_word.get(word_id.item()) for word_id in target_idx.cpu().numpy()])\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            predictions, true_vals = [], []\n",
    "            for context_idx, target_idx in dataloader:\n",
    "                context_idx, target_idx = context_idx.to(device), target_idx.to(device)\n",
    "                log_probs = model(target_idx)\n",
    "\n",
    "                # Get the index of the max log-probability\n",
    "                _, predicted_idx = torch.max(log_probs, dim=1)\n",
    "                predictions.extend([index_to_word.get(word_id.item()) for word_id in predicted_idx.cpu().numpy()])\n",
    "                \n",
    "                if include_true_vals:\n",
    "                    true_vals.extend([index_to_word.get(word_id.item()) for word_id in context_idx.cpu().numpy()])\n",
    "\n",
    "        \n",
    "                \n",
    "    if include_true_vals:\n",
    "        return predictions, true_vals\n",
    "    else:\n",
    "        return predictions\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_classification(model_type, prediction_val, prediction_test, y_val, y_test):\n",
    "    \"\"\"\n",
    "    Function that evaluates a classification model by computing accuracy, recall, precision, and F-score for the training and validation data, and optionally for the test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model_type : str\n",
    "        Type of the model being evaluated.\n",
    "    prediction_val : array\n",
    "        Predictions made by the model on the validation dataset.\n",
    "    prediction_test : array\n",
    "        Predictions made by the model on the test dataset.\n",
    "    y_val : array\n",
    "        Actual target values in the validation dataset.\n",
    "    y_test : array\n",
    "        Actual target values in the test dataset.\n",
    "    final_testing : bool, default=False\n",
    "        Flag indicating whether to evaluate the model on the test dataset.\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"\\n--------------------------\\n{model_type} Classification Evaluation \\n--------------------------\")\n",
    "\n",
    "\n",
    "    print(\"\\nValidation set\")\n",
    "    print(\"--------------\")\n",
    "\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_val, y_pred = prediction_val, average = 'micro'):.2f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true = y_val, y_pred = prediction_val):.2f}\")\n",
    "\n",
    "    #print(classification_report(y_true = y_val, y_pred = prediction_val, digits=2, zero_division=0))\n",
    "    print(\"\\nTest set\")\n",
    "    print(\"--------\\n\")\n",
    "    print(f\"F1 Score: {f1_score(y_true = y_test, y_pred = prediction_test, average = 'micro'):.2f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true = y_test, y_pred = prediction_test):.2f}\")\n",
    "\n",
    "    #print(classification_report(y_true = y_test, y_pred = prediction_test, digits=2, zero_division=0))\n",
    "    \n",
    "    \n",
    "def extract_embeddings(model_type = str, local_path = str, data_sample_name = str, index_to_word = dict):\n",
    "    model = load_best_model(model_type = model_type, local_path=local_path, data_sample_name = data_sample_name)\n",
    "    embeddings = model.embeddings.weight.detach().numpy()\n",
    "\n",
    "    # Create a DataFrame\n",
    "    embeddings_df = pd.DataFrame(embeddings)\n",
    "    embeddings_df.insert(0, 'word', [index_to_word[i] for i in range(len(embeddings_df))])\n",
    "    embeddings_df.to_csv(local_path + f\"data/embeddings/embeddings_{model_type}_{data_sample_name}.csv\")\n",
    "    return embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### Continuous bag of words model #####\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        # Embedding layer for word indices\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Linear layer for mapping embeddings to vocab size\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # Get embeddings for context words\n",
    "        embeds = self.embeddings(context)\n",
    "        # Average embeddings to get a single vector\n",
    "        combined = torch.mean(embeds, dim=1)\n",
    "        # Apply dropout and pass through linear layer\n",
    "        out = self.linear1(self.dropout(combined))\n",
    "        # Compute log probabilities\n",
    "        log_probs = torch.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "    \n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, target):\n",
    "        embeds = self.embeddings(target)\n",
    "        out = self.linear1(self.dropout(embeds))\n",
    "        log_probs = torch.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_corpus_train, filtered_corpus_val, filtered_corpus_test, word_to_index, index_to_word, data_sample_name = prepare_data_for_model_training(\n",
    "    file_name = \"comments\",\n",
    "    min_count = 6,\n",
    "    data_sample_name = \"all_2000\"    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#### Tuning ####\n",
    "## choose sample size and max epoch\n",
    "n_samples = 1\n",
    "epochs = 3\n",
    "\n",
    "## use the gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-16 23:04:15</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:35.92        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.5/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 3.000: -6.71<br>Logical resource usage: 2.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:GTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  context_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  min_delta</th><th style=\"text-align: right;\">  patience</th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_cbow_bb8ad_00000</td><td>TERMINATED</td><td>127.0.0.1:14676</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">             4</td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">            500</td><td style=\"text-align: right;\">     130</td><td style=\"text-align: right;\">   0.75</td><td style=\"text-align: right;\">0.000415858</td><td style=\"text-align: right;\"> 0.00335253</td><td style=\"text-align: right;\">         5</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">    0.00643463</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">           149.3</td><td style=\"text-align: right;\">  6.71</td><td style=\"text-align: right;\"> 0.0658991</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "\u001b[36m(train_model_cbow pid=14676)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=d:/dlss-project24/tuning_results/run_08-16_23_01/trial_bb8ad_00000/checkpoint_000000)\n",
      "2024-08-16 23:04:15,841\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-08-16 23:04:15,843\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to 'd:/dlss-project24/tuning_results/run_08-16_23_01' in 0.0123s.\n",
      "2024-08-16 23:04:15,860\tINFO tune.py:1039 -- Total run time: 156.14 seconds (155.91 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'model': 'CBOW', 'data_sample_name': 'all_2000', 'context_size': 4, 'dropout': 0.4, 'lr': 0.0004158581379650631, 'batch_size': 128, 'epochs': 130, 'patience': 5, 'min_delta': 0.0033525279374814984, 'gamma': 0.75, 'step_size': 5, 'weight_decay': 0.006434633085797139, 'embedding_dim': 500}\n",
      "Best trial final validation loss: 6.71\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model_cbow,\n",
    "    num_samples=n_samples,\n",
    "    train_corpus = filtered_corpus_train,\n",
    "    val_corpus = filtered_corpus_val,\n",
    "    word_to_index= word_to_index,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1},\n",
    "    parameter_space = {\n",
    "            \"model\": \"CBOW\",\n",
    "            \"data_sample_name\": data_sample_name,\n",
    "            \"context_size\": tune.choice([2, 3, 4, 5]),\n",
    "            \"dropout\": tune.choice([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([64, 128, 256, 512, 1024]),\n",
    "            \"epochs\": tune.choice(list(range(50, 150, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([100, 500, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n",
    "\n",
    "plot_loss_curve(\"CBOW\", local_path = local_path, data_sample_name = data_sample_name)\n",
    "\n",
    "embeddings_cbow_all_years = extract_embeddings(\n",
    "     model_type = \"CBOW\", \n",
    "     local_path=local_path, \n",
    "     data_sample_name = data_sample_name, \n",
    "     index_to_word = index_to_word\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "CBOW Classification Evaluation \n",
      "--------------------------\n",
      "\n",
      "Validation set\n",
      "--------------\n",
      "F1 Score: 0.09\n",
      "Accuracy: 0.09\n",
      "\n",
      "Test set\n",
      "--------\n",
      "\n",
      "F1 Score: 0.10\n",
      "Accuracy: 0.10\n"
     ]
    }
   ],
   "source": [
    "context_size = 2\n",
    "\n",
    "val_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_val, context_size)\n",
    "test_pairs_cbow = create_context_target_pairs_cbow(filtered_corpus_test, context_size)\n",
    "\n",
    "val_dataset_cbow = Word2VecDataset_cbow(val_pairs_cbow, word_to_index)\n",
    "test_dataset_cbow = Word2VecDataset_cbow(test_pairs_cbow, word_to_index)\n",
    "\n",
    "val_loader_cbow = DataLoader(val_dataset_cbow, batch_size=len(val_dataset_cbow), shuffle=False)\n",
    "test_loader_cbow = DataLoader(test_dataset_cbow, batch_size=len(test_dataset_cbow), shuffle=False)\n",
    "\n",
    "prediction_val_cbow, true_val_cbow = classify(\n",
    "    model_type=\"CBOW\", \n",
    "    dataloader = val_loader_cbow, \n",
    "    index_to_word=index_to_word, \n",
    "    data_sample_name = data_sample_name\n",
    "    )\n",
    "prediction_test_cbow, true_test_cbow = classify(\n",
    "    model_type=\"CBOW\", \n",
    "    dataloader = test_loader_cbow, \n",
    "    index_to_word=index_to_word,\n",
    "    data_sample_name = data_sample_name\n",
    "    )\n",
    "\n",
    "evaluate_classification(\n",
    "    model_type = \"CBOW\", \n",
    "    prediction_val = prediction_val_cbow, \n",
    "    prediction_test = prediction_test_cbow, \n",
    "    y_val = true_val_cbow, \n",
    "    y_test = true_test_cbow\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-16 23:10:42</td></tr>\n",
       "<tr><td>Running for: </td><td>00:06:19.90        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 3.000: None<br>Logical resource usage: 2.0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:GTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  context_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  min_delta</th><th style=\"text-align: right;\">  patience</th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_skipgram_1cc22_00000</td><td>RUNNING </td><td>127.0.0.1:11376</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">             2</td><td style=\"text-align: right;\">      0.5</td><td style=\"text-align: right;\">           1000</td><td style=\"text-align: right;\">      80</td><td style=\"text-align: right;\">    0.1</td><td style=\"text-align: right;\">0.00018487</td><td style=\"text-align: right;\">0.000282474</td><td style=\"text-align: right;\">        10</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">    0.00450475</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## clear gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "## tune\n",
    "tune_parameters(\n",
    "    train_model_skipgram,\n",
    "    num_samples=n_samples,\n",
    "    train_corpus = filtered_corpus_train,\n",
    "    val_corpus = filtered_corpus_val,\n",
    "    word_to_index= word_to_index,\n",
    "    max_num_epochs=epochs,\n",
    "    resources = {\"cpu\": 2, \"gpu\": 1},\n",
    "    parameter_space = {\n",
    "            \"model\": \"skipgram\",\n",
    "            \"data_sample_name\": data_sample_name,\n",
    "            \"context_size\": tune.choice([2, 3, 4, 5]),\n",
    "            \"dropout\": tune.choice([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"batch_size\": tune.choice([64, 128, 256, 512, 1024]),\n",
    "            \"epochs\": tune.choice(list(range(50, 150, 10))),\n",
    "            \"patience\": tune.choice([5, 10, 15]),\n",
    "            \"min_delta\": tune.loguniform(0.01, 0.0001),\n",
    "            \"gamma\": tune.choice([0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "            \"step_size\": tune.choice([5, 10, 20]),\n",
    "            \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"embedding_dim\": tune.choice([100, 500, 1000])\n",
    "            },\n",
    "    local_path = local_path + \"/tuning_results\"\n",
    "    )\n",
    "\n",
    "plot_loss_curve(\"skipgram\", local_path = local_path, data_sample_name = data_sample_name)\n",
    "\n",
    "embeddings_skipgram_all_years = extract_embeddings(\n",
    "     model_type = \"skipgram\", \n",
    "     local_path=local_path, \n",
    "     data_sample_name = data_sample_name, \n",
    "     index_to_word = index_to_word\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 2\n",
    "\n",
    "val_pairs_skipgram = create_context_target_pairs_skipgram(filtered_corpus_val, context_size)\n",
    "test_pairs_skipgram = create_context_target_pairs_skipgram(filtered_corpus_test, context_size)\n",
    "\n",
    "val_dataset_skipgram = Word2VecDataset_skipgram(val_pairs_skipgram, word_to_index)\n",
    "test_dataset_skipgram = Word2VecDataset_skipgram(test_pairs_skipgram, word_to_index)\n",
    "\n",
    "val_loader_skipgram = DataLoader(val_dataset_skipgram, batch_size=len(val_dataset_cbow), shuffle=False)\n",
    "test_loader_skipgram = DataLoader(test_dataset_skipgram, batch_size=len(test_dataset_skipgram), shuffle=False)\n",
    "\n",
    "prediction_val_skipgram, true_val_skipgram = classify(\n",
    "    model_type=\"skipgram\", \n",
    "    dataloader = val_loader_skipgram, \n",
    "    index_to_word=index_to_word,\n",
    "    data_sample_name = data_sample_name\n",
    "    )\n",
    "prediction_test_skipgram, true_test_skipgram = classify(\n",
    "    model_type=\"skipgram\", \n",
    "    dataloader = test_loader_skipgram, \n",
    "    index_to_word=index_to_word,\n",
    "    data_sample_name = data_sample_name\n",
    "    )\n",
    "\n",
    "evaluate_classification(\n",
    "    model_type = \"skipgram\", \n",
    "    prediction_val = prediction_val_skipgram, \n",
    "    prediction_test = prediction_test_skipgram,\n",
    "    y_val = true_val_skipgram, \n",
    "    y_test = true_test_skipgram\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
